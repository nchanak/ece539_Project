{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funny python functions in other files don't get refreshed unless restart kernel, below magic is witchcraft that kinda fixes problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom script imports for compartmentalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 06:10:14.655498: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-15 06:10:14.689699: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-15 06:10:15.307107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import visualization, preprocess, metrics, naive_autoencoder, analyze_compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if Tensorflow sees your GPU and has CUDA\n",
    "### Unnecessary unless you want to run large models on your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4052618660117580701\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14211350528\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11080056222649611341\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "]\n",
      "Built with CUDA: True\n",
      "Built with GPU support: True\n",
      "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 05:40:21.665640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 05:40:21.781556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 05:40:21.781591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 05:40:22.032562: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 05:40:22.032609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 05:40:22.032616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-04-15 05:40:22.032638: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 05:40:22.032662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 13553 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-04-15 05:40:22.035613: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 05:40:22.035642: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 05:40:22.035658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"Built with GPU support:\", tf.test.is_built_with_gpu_support())\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Model\n",
    "### Ensure when creating new model that you return the autoencoder itself as well as latent space encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3, 64, 64, 3)]    0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 3, 64, 64, 32)    896       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 3, 64, 64, 64)    18496     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " conv_lstm2d (ConvLSTM2D)    (None, 3, 64, 64, 64)     295168    \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 3, 64, 64, 64)    36928     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 3, 64, 64, 32)    18464     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 3, 64, 64, 3)     867       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 370,819\n",
      "Trainable params: 370,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 3\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 3\n",
    "\n",
    "autoencoder, encoder = naive_autoencoder.build_conv_lstm_autoencoder(\n",
    "    sequence_length=sequence_length,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    channels=channels\n",
    ")\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "### Resizes, normalizes, and formats data-splitting into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (37254, 3, 64, 64, 3)\n",
      "Validation data shape: (9314, 3, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "video_folder = \"extracted_videos\"\n",
    "\n",
    "# Preprocess the videos\n",
    "video_data, video_filenames = preprocess_videos_with_mapping(\n",
    "    video_folder=video_folder,\n",
    "    sequence_length=sequence_length,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    channels=channels\n",
    ")\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "split_index = int(0.8 * len(video_data))\n",
    "train_data = video_data[:split_index]\n",
    "val_data = video_data[split_index:]\n",
    "\n",
    "# Reshape the training and validation data to match the input shape of the autoencoder\n",
    "train_data = train_data.reshape((-1, sequence_length, height, width, channels))\n",
    "val_data = val_data.reshape((-1, sequence_length, height, width, channels))\n",
    "\n",
    "print(\"Train data shape:\", train_data.shape)  # Expected: (num_samples, sequence_length, height, width, channels)\n",
    "print(\"Validation data shape:\", val_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY RUN IF YOU'RE NATHAN OR WANT TO WASTE TIME\n",
    "\n",
    "Or I suppose if you make a small baby model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (37146, 3, 64, 64, 3)\n",
      "Validation data shape: (9287, 3, 64, 64, 3)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 13:52:01.078876: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2025-04-03 13:52:01.282855: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2025-04-03 13:52:01.282889: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2025-04-03 13:52:01.283137: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:317] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2025-04-03 13:52:01.815474: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fd9ee002930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-04-03 13:52:01.815508: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Ti SUPER, Compute Capability 8.9\n",
      "2025-04-03 13:52:01.854659: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-04-03 13:52:02.078465: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:344] Couldn't read CUDA driver version.\n",
      "2025-04-03 13:52:02.109425: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9287/9287 [==============================] - 382s 41ms/step - loss: 7.7424e-04 - val_loss: 3.6359e-04\n",
      "Epoch 2/10\n",
      "9287/9287 [==============================] - 361s 39ms/step - loss: 1.4463e-04 - val_loss: 5.4172e-05\n",
      "Epoch 3/10\n",
      "9287/9287 [==============================] - 360s 39ms/step - loss: 9.0927e-05 - val_loss: 3.7964e-05\n",
      "Epoch 4/10\n",
      "9287/9287 [==============================] - 363s 39ms/step - loss: 7.0415e-05 - val_loss: 2.9867e-04\n",
      "Epoch 5/10\n",
      "9287/9287 [==============================] - 362s 39ms/step - loss: 6.1055e-05 - val_loss: 4.0588e-05\n",
      "Epoch 6/10\n",
      "9287/9287 [==============================] - 360s 39ms/step - loss: 5.1567e-05 - val_loss: 1.7583e-05\n",
      "Epoch 7/10\n",
      "9287/9287 [==============================] - 361s 39ms/step - loss: 4.6759e-05 - val_loss: 1.6843e-05\n",
      "Epoch 8/10\n",
      "9287/9287 [==============================] - 361s 39ms/step - loss: 4.2643e-05 - val_loss: 3.3355e-05\n",
      "Epoch 9/10\n",
      "9287/9287 [==============================] - 360s 39ms/step - loss: 3.9196e-05 - val_loss: 5.7956e-05\n",
      "Epoch 10/10\n",
      "9287/9287 [==============================] - 360s 39ms/step - loss: 3.3616e-05 - val_loss: 1.2270e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fde79ba0730>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "autoencoder.fit(\n",
    "    train_data, train_data,\n",
    "    validation_data=(val_data, val_data),\n",
    "    epochs=10,\n",
    "    batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If have multiple autoencoders trained, can change name to load different one\n",
    "encoder_file = \"video_autoencoder.keras\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVES ENCODER. ONLY USE IF YOU'VE JUST TRAINED A MODEL YOU WANT TO KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "autoencoder.save(encoder_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADS MODEL, PROBABLY ALWAYS DO THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "autoencoder = load_model(encoder_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It's the metrics, wtf else is there to say"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nchanak/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/nchanak/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/nchanak/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'psnr': 39.454144, 'ssim': 0.9577416, 'lpips': 0.011201685887672716}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.compute_video_metrics(video_path=\"comparison_celebv_-_Bdf9C0SAU_0.avi\", frame_width=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression\n",
    "### Yes very bad compression rn cuz latent space huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[â–¶] Processing 82 sequences from: celebv_-3KCgSpt3hU_5.mp4\n",
      "82/82 [==============================] - 0s 4ms/step\n",
      "82/82 [==============================] - 0s 5ms/step\n",
      "\n",
      "ðŸ“¦ Compression Results for 'celebv_-3KCgSpt3hU_5.mp4':\n",
      "Raw 64x64 input size:    558.52 KB\n",
      "Latent compressed size:  148215.69 KB\n",
      "Estimated compression:   0.00x\n"
     ]
    }
   ],
   "source": [
    "import analyze_compression\n",
    "\n",
    "# Assume you've already run\n",
    "# autoencoder, encoder = build_conv_lstm_autoencoder(...)\n",
    "# autoencoder.load_weights(...)\n",
    "# video_data, video_filenames = preprocess_videos_with_mapping(...)\n",
    "\n",
    "result = analyze_compression.analyze_compression_from_video_file(\n",
    "    video_name=\"celebv_-3KCgSpt3hU_5.mp4\",\n",
    "    autoencoder=autoencoder,\n",
    "    encoder=encoder,\n",
    "    sequence_length=3,\n",
    "    height=64,\n",
    "    width=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "requires: conda install -c conda-forge ffmpeg\n",
    "\n",
    "alternatively: sudo apt install ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 170ms/step\n",
      "[âœ“] Comparison saved: comparison_celebv_-3KCgSpt3hU_5.avi\n",
      "[â–¶] Converting comparison_celebv_-3KCgSpt3hU_5.avi â†’ comparison_celebv_-3KCgSpt3hU_5.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, avi, from 'comparison_celebv_-3KCgSpt3hU_5.avi':\n",
      "  Metadata:\n",
      "    software        : Lavf59.27.100\n",
      "  Duration: 00:00:03.46, start: 0.000000, bitrate: 203 kb/s\n",
      "  Stream #0:0: Video: mpeg4 (Simple Profile) (XVID / 0x44495658), yuv420p, 128x64 [SAR 1:1 DAR 2:1], 187 kb/s, 24 fps, 24 tbr, 24 tbn, 24 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x555f9b0df9c0] using SAR=1/1\n",
      "[libx264 @ 0x555f9b0df9c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "[libx264 @ 0x555f9b0df9c0] profile High, level 2.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x555f9b0df9c0] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=8 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'comparison_celebv_-3KCgSpt3hU_5.mp4':\n",
      "  Metadata:\n",
      "    software        : Lavf59.27.100\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 512x256 [SAR 1:1 DAR 2:1], q=2-31, 24 fps, 12288 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=   83 fps=0.0 q=-1.0 Lsize=     148kB time=00:00:03.33 bitrate= 363.9kbits/s speed=23.7x    \n",
      "video:146kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.250184%\n",
      "[libx264 @ 0x555f9b0df9c0] frame I:1     Avg QP:23.71  size:  5725\n",
      "[libx264 @ 0x555f9b0df9c0] frame P:22    Avg QP:24.03  size:  3616\n",
      "[libx264 @ 0x555f9b0df9c0] frame B:60    Avg QP:27.76  size:  1063\n",
      "[libx264 @ 0x555f9b0df9c0] consecutive B-frames:  3.6%  0.0%  0.0% 96.4%\n",
      "[libx264 @ 0x555f9b0df9c0] mb I  I16..4:  9.0% 85.5%  5.5%\n",
      "[libx264 @ 0x555f9b0df9c0] mb P  I16..4:  1.9%  9.4%  0.2%  P16..4: 41.7% 22.9%  9.7%  0.0%  0.0%    skip:14.2%\n",
      "[libx264 @ 0x555f9b0df9c0] mb B  I16..4:  0.0%  0.2%  0.0%  B16..8: 32.5%  5.1%  1.4%  direct: 7.8%  skip:53.0%  L0:51.1% L1:38.5% BI:10.4%\n",
      "[libx264 @ 0x555f9b0df9c0] 8x8 transform intra:82.8% inter:78.5%\n",
      "[libx264 @ 0x555f9b0df9c0] coded y,uvDC,uvAC intra: 69.6% 47.6% 1.0% inter: 25.4% 10.2% 0.0%\n",
      "[libx264 @ 0x555f9b0df9c0] i16 v,h,dc,p: 38% 11% 10% 41%\n",
      "[libx264 @ 0x555f9b0df9c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 26%  9% 18%  5% 10% 13%  6%  8%  6%\n",
      "[libx264 @ 0x555f9b0df9c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 36% 15% 15%  5%  8%  9%  4%  4%  3%\n",
      "[libx264 @ 0x555f9b0df9c0] i8c dc,h,v,p: 56% 13% 26%  6%\n",
      "[libx264 @ 0x555f9b0df9c0] Weighted P-Frames: Y:4.5% UV:0.0%\n",
      "[libx264 @ 0x555f9b0df9c0] ref P L0: 49.6% 11.1% 23.1% 14.6%  1.6%\n",
      "[libx264 @ 0x555f9b0df9c0] ref B L0: 82.6% 11.4%  6.0%\n",
      "[libx264 @ 0x555f9b0df9c0] ref B L1: 97.3%  2.7%\n",
      "[libx264 @ 0x555f9b0df9c0] kb/s:344.79\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <video width=\"512\" height=\"256\" controls>\n",
       "      <source src=\"comparison_celebv_-3KCgSpt3hU_5.mp4\" type=\"video/mp4\">\n",
       "      Your browser does not support the video tag.\n",
       "    </video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_video = \"celebv_-3KCgSpt3hU_5.mp4\"\n",
    "\n",
    "comparison_video = visualization.generate_video_comparison_by_name(\n",
    "    video_name=play_video,\n",
    "    autoencoder=autoencoder,\n",
    "    sequence_length=sequence_length,\n",
    "    height=height,\n",
    "    width=width\n",
    ")\n",
    "mp4_file = visualization.convert_avi_to_mp4(comparison_video, scale=4)\n",
    "visualization.display_video_inline(mp4_file, width=512)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU (WSL)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
