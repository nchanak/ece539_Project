{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e67c5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9184d0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 01:36:31.691469: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-16 01:36:31.927798: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-16 01:36:31.927858: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-16 01:36:31.929248: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-16 01:36:32.033290: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-16 01:36:32.845588: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/nchanak/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import visualization, preprocess, metrics, naive_autoencoder, analyze_compression, wip_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8419a79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8865989614041999463\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14211350528\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2546555541409946512\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "]\n",
      "Built with CUDA: True\n",
      "Built with GPU support: True\n",
      "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 01:36:50.341551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-16 01:36:50.462280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-16 01:36:50.462316: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-16 01:36:50.603549: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-16 01:36:50.603590: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-16 01:36:50.603597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-04-16 01:36:50.603623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-16 01:36:50.603638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 13553 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-04-16 01:36:50.606365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-16 01:36:50.606390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-16 01:36:50.606406: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"Built with GPU support:\", tf.test.is_built_with_gpu_support())\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aff570a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "# Clear TF session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Run garbage collection\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a5aacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 4\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ead2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 01:36:58.302919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-16 01:36:58.302989: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-16 01:36:58.303015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-16 01:36:58.303262: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-16 01:36:58.303274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-04-16 01:36:58.303300: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-16 01:36:58.303312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13553 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PixelCNN input shape (T, H, W): (2, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define your input shape for the video sequences\n",
    "input_shape = (sequence_length, height, width, channels)\n",
    "\n",
    "# Build encoder and decoder\n",
    "encoder = wip_model.build_encoder(input_shape=input_shape, latent_channels=32)\n",
    "decoder = wip_model.build_decoder(latent_shape=encoder.output_shape[1:], output_channels=3)\n",
    "\n",
    "# Vector quantization layer\n",
    "vq_layer = wip_model.VectorQuantizer(num_embeddings=256, embedding_dim=32)\n",
    "\n",
    "# Get latent shape without embedding dimension for PixelCNNPrior input\n",
    "z_index_shape = encoder.output_shape[1:-1]  # (T, H, W)\n",
    "print(\"PixelCNN input shape (T, H, W):\", z_index_shape)\n",
    "\n",
    "# Build PixelCNN prior\n",
    "pixelcnn_prior = wip_model.PixelCNNPrior(input_shape=z_index_shape, num_embeddings=256)\n",
    "\n",
    "# Compose the full VQ-VAE module\n",
    "vqvae = wip_model.VQVAEModule(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    vq_layer=vq_layer,\n",
    "    pixelcnn_prior=pixelcnn_prior,\n",
    "    beta=1.0\n",
    ")\n",
    "\n",
    "# Compile with optimizer\n",
    "vqvae.compile(optimizer=tf.keras.optimizers.Adam(1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d41e1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (3128, 4, 64, 64, 3)\n",
      "Validation data shape: (782, 4, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "video_folder = \"extracted_videos\"\n",
    "\n",
    "# Preprocess the videos\n",
    "video_data, video_filenames = preprocess.preprocess_videos_with_mapping(\n",
    "    video_folder=video_folder,\n",
    "    sequence_length=sequence_length,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    channels=channels\n",
    ")\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "split_index = int(0.8 * len(video_data))\n",
    "train_data = video_data[:split_index]\n",
    "val_data = video_data[split_index:]\n",
    "\n",
    "# Reshape the training and validation data to match the input shape of the autoencoder\n",
    "train_data = train_data.reshape((-1, sequence_length, height, width, channels))\n",
    "val_data = val_data.reshape((-1, sequence_length, height, width, channels))\n",
    "train_data = train_data.astype(np.float32)\n",
    "val_data = val_data.astype(np.float32)\n",
    "\n",
    "print(\"Train data shape:\", train_data.shape)  # Expected: (num_samples, sequence_length, height, width, channels)\n",
    "print(\"Validation data shape:\", val_data.shape)\n",
    "\n",
    "# Preprocessing for WIP model, not necessary to run currently\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def make_dataset(array, batch_size=4, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(array.astype(np.float32))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_dataset(train_data, batch_size=8)\n",
    "val_ds = make_dataset(val_data, batch_size=8, shuffle=False)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train_data).batch(8).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = tf.data.Dataset.from_tensor_slices(val_data).batch(8).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77097e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "# Output directory setup\n",
    "run_name = \"vqvae_video_compression\"\n",
    "output_dir = os.path.join(\"training_runs\", run_name)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\n",
    "    ModelCheckpoint(\n",
    "    filepath=os.path.join(output_dir, \"best_weights\"),\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    "    ),\n",
    "    TensorBoard(log_dir=os.path.join(output_dir, \"logs\"))\n",
    "]\n",
    "\n",
    "history = vqvae.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=7,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff6f2084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Weights loaded from: training_runs/vqvae_video_compression/best_weights\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Loads the wip model weights\n",
    "weights_path = os.path.join(\"training_runs\", \"vqvae_video_compression\", \"best_weights\")\n",
    "vqvae.load_weights(weights_path)\n",
    "print(\"âœ“ Weights loaded from:\", weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be271fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 01:37:45.560252: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2025-04-16 01:37:45.560281: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2025-04-16 01:37:45.560317: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:45.616811: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2025-04-16 01:37:45.778361: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:322] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2025-04-16 01:37:45.852077: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/99 [========>.....................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 01:37:46.091463: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 1s 5ms/step\n",
      "ðŸ“¹ Evaluating: celebv_-_Bdf9C0SAU_8.mp4 â€” 99 sequences\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nchanak/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/nchanak/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/nchanak/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 01:37:47.237244: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.237282: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.237633: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.238219: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.238369: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.238988: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.239705: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.239753: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.354616: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.442079: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.442335: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.442378: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.442911: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.442993: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.443044: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.450246: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-16 01:37:47.457930: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 1s 6ms/step\n",
      "ðŸ“¹ Evaluating: celebv_-_Bdf9C0SAU_3.mp4 â€” 121 sequences\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/nchanak/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "94/94 [==============================] - 0s 5ms/step\n",
      "ðŸ“¹ Evaluating: celebv_-_Bdf9C0SAU_9.mp4 â€” 94 sequences\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/nchanak/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'celebv_-_Bdf9C0SAU_8.mp4': {'psnr': 26.858852,\n",
       "  'ssim': 0.69074017,\n",
       "  'lpips': 0.2320852018516473},\n",
       " 'celebv_-_Bdf9C0SAU_3.mp4': {'psnr': 27.10564,\n",
       "  'ssim': 0.7171877,\n",
       "  'lpips': 0.23039042977385285},\n",
       " 'celebv_-_Bdf9C0SAU_9.mp4': {'psnr': 25.9784,\n",
       "  'ssim': 0.7215839,\n",
       "  'lpips': 0.2221118190345612}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_val = metrics.evaluate_metrics_by_video(\n",
    "    split=\"val\",\n",
    "    limit=3,\n",
    "    video_data=video_data,\n",
    "    video_filenames=video_filenames,\n",
    "    autoencoder=vqvae,\n",
    "    sequence_length=sequence_length,\n",
    "    height=height,\n",
    "    width=width\n",
    ")\n",
    "metrics_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27253606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating compression on 3 val videos...\n",
      "\n",
      "99/99 [==============================] - 3s 25ms/step\n",
      "267/267 [==============================] - 7s 25ms/step\n",
      "94/94 [==============================] - 2s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'celebv_-_Bdf9C0SAU_8.mp4': {'video': 'celebv_-_Bdf9C0SAU_8.mp4',\n",
       "  'num_sequences': 99,\n",
       "  'num_frames': 396,\n",
       "  'input_kb_estimated': 3282.0314071120415,\n",
       "  'codec_kb': 36.412109375,\n",
       "  'latent_kb_estimated': 13.292874336242676,\n",
       "  'compression_ratio_codec': 90.13571208718368,\n",
       "  'compression_ratio_latent': 246.90155974495812,\n",
       "  'vq_time_secs': 3.053363561630249},\n",
       " 'celebv_-_Bdf9C0SAU_3.mp4': {'video': 'celebv_-_Bdf9C0SAU_3.mp4',\n",
       "  'num_sequences': 267,\n",
       "  'num_frames': 1068,\n",
       "  'input_kb_estimated': 9001.780255015248,\n",
       "  'codec_kb': 134.998046875,\n",
       "  'latent_kb_estimated': 34.84114074707031,\n",
       "  'compression_ratio_codec': 66.68081845176879,\n",
       "  'compression_ratio_latent': 258.3664042565019,\n",
       "  'vq_time_secs': 7.863688945770264},\n",
       " 'celebv_-_Bdf9C0SAU_9.mp4': {'video': 'celebv_-_Bdf9C0SAU_9.mp4',\n",
       "  'num_sequences': 94,\n",
       "  'num_frames': 376,\n",
       "  'input_kb_estimated': 3259.8387960985624,\n",
       "  'codec_kb': 31.8603515625,\n",
       "  'latent_kb_estimated': 12.690022468566895,\n",
       "  'compression_ratio_codec': 102.31647286451886,\n",
       "  'compression_ratio_latent': 256.88203501397754,\n",
       "  'vq_time_secs': 2.762380599975586}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import analyze_compression\n",
    "\n",
    "importlib.reload(analyze_compression)\n",
    "with tf.device('/CPU:0'):\n",
    "    compression_results = analyze_compression.evaluate_compression_by_video(\n",
    "        split=\"val\",\n",
    "        limit=3,\n",
    "        video_data=video_data,\n",
    "        video_filenames=video_filenames,\n",
    "        autoencoder=vqvae,\n",
    "        encoder=encoder,\n",
    "        sequence_length=sequence_length,\n",
    "        height=height,\n",
    "        width=width\n",
    "    )\n",
    "compression_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d886d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video = \"celebv_-_Bdf9C0SAU_6.mp4\"\n",
    "\n",
    "visualization.generate_and_display_comparison(\n",
    "    video_name=play_video,\n",
    "    autoencoder=vqvae,\n",
    "    sequence_length=sequence_length,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    cleanup=True \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU (WSL)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
